{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过学习曲线检测过拟合和欠拟合\n",
    "\n",
    "对于这道测验，我们将使用三个模型来训练下面的圆形数据集。\n",
    "\n",
    "- 决策树模型，\n",
    "- 逻辑回归模型，以及\n",
    "- 支持向量机模型。\n",
    "\n",
    "<img src=\"../../../files/img/model/circle-data.png\">\n",
    "\n",
    "其中一个模型会过拟合，一个欠拟合，还有一个正常。首先，我们将编写代码为每个模型绘制学习曲线，最后我们将查看这些学习曲线，判断每个模型对应哪个曲线。\n",
    "\n",
    "首先，请记住三个模型的学习曲线外观如下所示：\n",
    "\n",
    "<img src=\"../../../files/img/model/learning-curves.png\">\n",
    "\n",
    "对于这道测验的第一部分，你只需取消注释其中一个分类器，并点击'测试答案'以查看学习曲线的图表。但是如果你喜欢编程的话，以下是一些编程详情。我们将使用函数 `learning_curve`：\n",
    "\n",
    "```\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator, X, y, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "```\n",
    "\n",
    "不需要担心该函数的所有参数（你可以在 [此处](http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html) 了解详情），这里，我们将解释主要参数：\n",
    "\n",
    "- estimator，是我们针对数据使用的实际分类器，例如 LogisticRegression() 或 GradientBoostingClassifier()。\n",
    "X 和 y 是我们的数据，分别表示特征和标签。\n",
    "- train_sizes 是用来在曲线上绘制每个点的数据大小。\n",
    "- train_scores 是针对每组数据进行训练后的算法训练得分。\n",
    "- test_scores 是针对每组数据进行训练后的算法测试得分。\n",
    "\n",
    "两个重要的现象：\n",
    "\n",
    "- 训练和测试得分是一个包含 3 个值的列表，这是因为函数使用了 3 折交叉验证。\n",
    "- *非常重要*：可以看出，我们使用训练和测试误差来定义我们的曲线，而这个函数使用训练和测试得分来定义曲线。二者是相反的，因此误差越高，得分就越低。因此，当你看到曲线时，你需要自己在脑中将它颠倒过来，以便与上面的曲线对比。\n",
    "\n",
    "\n",
    "## 第 1 部分：绘制学习曲线\n",
    "\n",
    "这里，我们将对比三个模型：\n",
    "\n",
    "- 逻辑回归模型。\n",
    "- 决策树模型。\n",
    "- 支持向量机模型，具有 RBF 内核，γ 参数为 1000（稍后我们将了解它们的含义）。\n",
    "\n",
    "取消注释每个的代码，并检查所绘制的学习曲线。如果你对绘制学习曲线用到的代码感兴趣，请查看utils.py标签页。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, read, and split data\n",
    "import pandas as pd\n",
    "data = pd.read_csv('../../../files/data/test_model/sklearn_classifier_test_model_data.csv')\n",
    "import numpy as np\n",
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])\n",
    "\n",
    "# Fix random seed\n",
    "np.random.seed(55)\n",
    "\n",
    "### Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO: Uncomment one of the three classifiers, and hit \"Test Run\"\n",
    "# to see the learning curve. Use these to answer the quiz below.\n",
    "\n",
    "## Logistic Regression\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "### Decision Tree\n",
    "#estimator = GradientBoostingClassifier()\n",
    "\n",
    "### Support Vector Machine\n",
    "#estimator = SVC(kernel='rbf', gamma=1000)\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator, X, y, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# It is good to randomize the data before drawing Learning Curves\n",
    "def randomize(X, Y):\n",
    "    permutation = np.random.permutation(Y.shape[0])\n",
    "    X2 = X[permutation,:]\n",
    "    Y2 = Y[permutation]\n",
    "    return X2, Y2\n",
    "\n",
    "X2, y2 = randomize(X, y)\n",
    "\n",
    "def draw_learning_curves(X, y, estimator, num_trainings):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X2, y2, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.title(\"Learning Curves\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    plt.plot(train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(test_scores_mean, 'o-', color=\"y\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第 2 部分：分析学习曲线\n",
    "\n",
    "对于该测验的第 2 部分，你可以查看你之前绘制的曲线并判断三个模型中哪个模型欠拟合，哪个过拟合，哪个正好。\n",
    "\n",
    "## 练习题\n",
    "\n",
    "根据上述模型曲线，哪个模型欠拟合，哪个过拟合，哪个正好？\n",
    "\n",
    "- 对数几率回归\n",
    "- 支持向量机\n",
    "- 决策树\n",
    "\n",
    "对应的\n",
    "\n",
    "- 过拟合\n",
    "- 欠拟合\n",
    "- 正好\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
