{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"550\" src=\"https://www.youtube.com/embed/yQvnv7l_aUo\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"900\" height=\"550\" src=\"https://www.youtube.com/embed/yQvnv7l_aUo\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM Cell\n",
    "- GRU Cell    门控循环单元\n",
    "- Valilla RNN Cell\n",
    "\n",
    "LSTM和GRU的性能都高于valilla\n",
    "\n",
    "## LSTM 与 GRU 对比\n",
    "\n",
    "\"这些结果清楚地表明了门控单元较于传统循环单元的优点。收敛往往更快，而且最终的解决方案往往会更好。但是，我们的结果在 比较 LSTM 和 GRU 方面并非决定性的，这表明门控循环单元类型的选择可能在很大程度上取决于数据集和相应的任务。\"\n",
    "\n",
    "[根据序列建模的门控循环神经网络的实证评估](https://arxiv.org/abs/1412.3555)，作者：Junyoung Chung、Caglar Gulcehre、KyungHyun Cho、Yoshua Bengio\n",
    "\n",
    "\"除了语言建模，GRU 在所有任务上都胜过了 LSTM\"\n",
    "\n",
    "[循环网络架构的实证](http://proceedings.mlr.press/v37/jozefowicz15.pdf)探索作者：Rafal Jozefowicz、Wojciech Zaremba、Ilya Sutskever\n",
    "\n",
    "\"我们一致的发现是至少两层的深度是有益的。但是，在两层和三层之间，我们的结果不太一致。此外，LSTM 和 GRU 之间的结果也不一致，但都显著优于 RNN。\"\n",
    "\n",
    "[可视化和理解循环网络](https://arxiv.org/abs/1506.02078)，作者：Andrej Karpathy、Justin Johnson、Li Fei-Fei\n",
    "\n",
    "\"哪些变体最好？它们的差异是否重要？[Greff, et al. (2015)](https://arxiv.org/pdf/1503.04069.pdf) 对常用的变体进行了详尽的对比，发现它们都差不多一样。[Jozefowicz, et al. (2015)](http://proceedings.mlr.press/v37/jozefowicz15.pdf) 测试了超过一万个 RNN 架构，发现某些在特定任务上的性能优于 LSTM。\"\n",
    "\n",
    "[理解 LSTM 网络](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)，作者：Chris Olah\n",
    "\n",
    "\n",
    "RNN 架构示例\n",
    "- 应用\tCell\t层\t大小\t词汇\t嵌入大小\t学习率\t\n",
    "- 语音识别（大词汇表）\tLSTM\t5, 7\t600, 1000\t82K, 500K\t--\t--\t[paper](https://arxiv.org/abs/1610.09975)\n",
    "- 语音识别\tLSTM\t1, 3, 5\t250\t--\t--\t0.001\t[paper](https://arxiv.org/abs/1303.5778)\n",
    "- 机器翻译 (seq2seq)\tLSTM\t4\t1000\t原词汇：160K，目标词汇：80K\t1,000\t--\t[paper](https://arxiv.org/abs/1409.3215)\n",
    "- 图片字幕\tLSTM\t--\t512\t--\t512\t(固定)\t[paper](https://arxiv.org/abs/1411.4555)\n",
    "- 图像生成\tLSTM\t--\t256, 400, 800\t--\t--\t--\t[paper](https://arxiv.org/abs/1502.04623)\n",
    "- 问题回答\tLSTM\t2\t500\t--\t300\t--\t[pdf](http://www.aclweb.org/anthology/P15-2116)\n",
    "- 文本总结\tGRU\t\t200\t原词汇：119K，目标词汇：68K\t100\t0.001\t[pdf](https://pdfs.semanticscholar.org/3fbc/45152f20403266b02c4c2adab26fb367522d.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
