{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改进你的 GAN\n",
    "\n",
    "我向你展示的 GAN，在生成器和辨别器中只使用了一个隐藏层。这个 GAN 的结果已经非常不错了，但仍然有很多噪声图像，以及有些图像看起来不太像数字。但是，要让生成器生成的图像与 MNIST 数据集几乎一样，是完全可能的。\n",
    "\n",
    "<img src=\"../../../sources/img/GAN/generated-mnist.png\">\n",
    "\n",
    "<center> 经训练的 GAN 生成的 MNIST 图像 (https://arxiv.org/pdf/1606.03498.pdf) </center>\n",
    "    \n",
    "这来自一篇题为 [Improved Techniques for Training GANs](https://arxiv.org/pdf/1606.03498.pdf) 的文章。那么，它们如何生成如此美观的图像呢？\n",
    "\n",
    "与大多数神经网络一样，使用的层越多，网络的性能就越好。所以你可以尝试两三层，而不只是一层。尝试使用有更多单元的更大的层，看看它对你的结果有何影响。\n",
    "\n",
    "## 批归一化\n",
    "\n",
    "提醒一下，在三层情况下你可能无法使它很好地工作。网络会变得对权重的初始值非常敏感，导致无法训练。我们可以使用 [批归一化（Batch Normalization）](https://arxiv.org/abs/1502.03167) 来解决这个问题。原理很简单。就像我们对网络输入的做法一样，我们可以对每个层的输入进行归一化。也就是说，缩放层输入，使它具有零均值和标准差 1。经发现，批归一化对于构建深度 GAN 非常有必要。\n",
    "\n",
    "我们将在下一周的课程中讲解批归一化，以及对生成器和辨别器使用卷积网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
