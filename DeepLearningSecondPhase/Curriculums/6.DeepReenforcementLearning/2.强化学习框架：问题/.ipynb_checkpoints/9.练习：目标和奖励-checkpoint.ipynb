{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习：目标和奖励\n",
    "\n",
    "到目前为止，你已经见过一个如何将智能体的目标构建为最大化预期累积奖励的示例。在这道练习中，你将研究另外几个示例。\n",
    "\n",
    "<img src=\"../../../sources/img/RL/maze_line.png\">\n",
    "\n",
    "\n",
    "## 练习题\n",
    "\n",
    "假设有一个智能体想要学会逃脱迷宫。哪些奖励信号将鼓励智能体尽快逃脱迷宫？请选中所有适用项。\n",
    "\n",
    "- 智能体待在迷宫中的每个时间步，奖励都是 -1。智能体逃脱后，这个阶段结束。\n",
    "- 智能体待在迷宫中的每个时间步，奖励都是 +1。智能体逃脱后，这个阶段结束。\n",
    "- 智能体待在迷宫中的每个时间步，奖励都是 -1。智能体逃脱后，获得奖励 +10，并且这个阶段结束。\n",
    "- 智能体待在迷宫中的每个时间步，奖励都是 0。智能体逃脱后，获得奖励 +1，并且这个阶段结束。\n",
    "\n",
    "<img src=\"../../../sources/img/RL/backgammonboard.svg.png\">\n",
    "\n",
    "‘假设有一个智能体想要玩棋类游戏（例如双陆棋、象棋或跳棋）。哪些奖励信号将鼓励智能体赢得游戏？请选中所有适用项。'\n",
    "\n",
    "- 智能体仅在游戏结束时获得奖励；如果获胜，则获得奖励 +1，如果失败了，则获得奖励 -1，如果持平，则获得奖励 0。\n",
    "- 在依然玩游戏的每个时间步，智能体获得奖励 -1；游戏结束后，这一阶段结束。\n",
    "- 智能体仅在游戏结束时获得奖励，如果获胜，获得奖励 -1，如果失败，获得奖励 +1，如果持平，获得奖励 0。\n",
    "- 智能体仅在游戏结束时获得奖励，如果获胜，获得奖励 +10，如果失败，获得奖励 -10，如果持平，获得奖励 0。\n",
    "\n",
    "<img src=\"../../../sources/img/RL/dog_with_plate.jpg\">\n",
    "\n",
    "假设有一个智能体想要使她头上的碟子保持平衡。哪些奖励信号将鼓励智能体尽量使碟子保持平衡？请选中所有适用项。\n",
    "\n",
    "- 在每个时间步，当智能体使头上的碟子保持平衡时，奖励是 -1。如果碟子掉下来了，这一阶段结束。\n",
    "- 在每个时间步，当智能体使头上的碟子保持平衡时，奖励是 +1。如果碟子掉下来了，这一阶段结束。\n",
    "- 仅当碟子掉下来时，智能体会获得奖励。如果碟子没有摔碎，智能体获得奖励 +1。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
