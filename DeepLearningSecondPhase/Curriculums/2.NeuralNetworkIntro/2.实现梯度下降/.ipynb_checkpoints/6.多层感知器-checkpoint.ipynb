{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/Rs9petvTBLk\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"800\" height=\"450\" src=\"https://www.youtube.com/embed/Rs9petvTBLk\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现隐藏层\n",
    "\n",
    "先修要求\n",
    "接下来我们会讲神经网络在多层感知器里面的数学部分。讲多层感知器我们会用到向量和矩阵。你可以通过下列讲解对此做个回顾：\n",
    "\n",
    "- 可汗学院的 [向量入门](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/vectors/v/vector-introduction-linear-algebra).\n",
    "- 可汗学院的 [矩阵入门](https://www.khanacademy.org/math/precalculus/precalc-matrices).\n",
    "\n",
    "## 由来\n",
    "\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-1.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/network-with-labeled-nodes.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-2.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/network-with-labeled-weights.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-3.png\">\n",
    "\n",
    "对比上面的示意图，确保你了解了不同的权重在矩阵中与在神经网络中的对应关系。\n",
    "\n",
    "用 NumPy 来初始化这些权重，我们需要提供矩阵的形状（shape），如果特征是一个包含以下数据的二维数组：\n",
    "\n",
    "```\n",
    "# Number of records and input units\n",
    "# 数据点数量以及每个数据点有多少输入节点\n",
    "n_records, n_inputs = features.shape\n",
    "# Number of hidden units\n",
    "# 隐藏层节点个数\n",
    "n_hidden = 2\n",
    "weights_input_to_hidden = np.random.normal(0, n_inputs**-0.5, size=(n_inputs, n_hidden))\n",
    "```\n",
    "\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-4.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/input-times-weights.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-5.png\">\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/multi-perceptron-text-6.png\">\n",
    "\n",
    "```\n",
    "# Same weights and features as above, but swapped the order\n",
    "hidden_inputs = np.dot(weights_input_to_hidden, features)\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "<ipython-input-11-1bfa0f615c45> in <module>()\n",
    "----> 1 hidden_in = np.dot(weights_input_to_hidden, X)\n",
    "\n",
    "ValueError: shapes (3,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)\n",
    "```\n",
    "\n",
    "3x2 的矩阵跟 3 个元素的数组是没法相乘的。因为矩阵中的两列与数组中的元素个数并不匹配。能够相乘的矩阵如下：\n",
    "\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/gradient-descent/matrix-mult-3.png\">\n",
    "\n",
    "\n",
    "这里的规则是，如果是数组在左边，数组的元素个数必须与右边矩阵的行数一样。如果矩阵在左边，那么矩阵的列数，需要与右边向量的行数匹配。\n",
    "\n",
    "## 构建一个列向量\n",
    "\n",
    "看上面的介绍，你有时会需要一个列向量，尽管 NumPy 默认是行向量。你可以用 `arr.T` 来对数组进行转置，但对一维数组来说，转置还是行向量。所以你可以用 `arr[:,None]` 来创建一个列向量：\n",
    "\n",
    "```\n",
    "print(features)\n",
    "> array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
    "\n",
    "print(features.T)\n",
    "> array([ 0.49671415, -0.1382643 ,  0.64768854])\n",
    "\n",
    "print(features[:, None])\n",
    "> array([[ 0.49671415],\n",
    "       [-0.1382643 ],\n",
    "       [ 0.64768854]])\n",
    "```\n",
    "\n",
    "当然，你可以创建一个二维数组，然后用 `arr.T` 得到列向量。\n",
    "\n",
    "```\n",
    "np.array(features, ndmin=2)\n",
    "> array([[ 0.49671415, -0.1382643 ,  0.64768854]])\n",
    "\n",
    "np.array(features, ndmin=2).T\n",
    "> array([[ 0.49671415],\n",
    "       [-0.1382643 ],\n",
    "       [ 0.64768854]])\n",
    "```\n",
    "\n",
    "我个人更倾向于保持所有向量为一维数组，这样可以更好认知。\n",
    "\n",
    "## 编程练习\n",
    "\n",
    "下面你要实现一个 4x3x2 网络的正向传播，用 sigmoid 作为两层的激活函数。\n",
    "\n",
    "## 要做的事情：\n",
    "\n",
    "- 计算隐藏层的输入\n",
    "- 计算隐藏层输出\n",
    "- 计算输出层的输入\n",
    "- 计算神经网络的输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[ 0.41492192  0.42604313  0.5002434 ]\n",
      "Output-layer Output:\n",
      "[ 0.49815196  0.48539772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "weights_input_to_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_to_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "# 计算隐藏层的输入\n",
    "hidden_layer_in = np.dot(X, weights_input_to_hidden)\n",
    "# 计算隐藏层的输出\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "# 计算输出层的输入\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_to_output)\n",
    "# 计算神经网络的输出\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
