{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用 Keras 构建神经网络\n",
    "\n",
    "幸运的是，每次我们需要使用神经网络时，都不需要编写激活函数、梯度下降等。有很多包可以帮助我们，建议你了解这些包，包括以下包：\n",
    "\n",
    "- [Keras](https://keras.io/)\n",
    "- [TensorFlow](https://www.tensorflow.org/)\n",
    "- [Caffe](http://caffe.berkeleyvision.org/)\n",
    "- [Theano](http://deeplearning.net/software/theano/)\n",
    "- [Scikit-learn](http://scikit-learn.org/)\n",
    "- [PyTorch](http://pytorch.org/)\n",
    "- 以及很多其他包！\n",
    "\n",
    "\n",
    "在这门课程中，我们将学习 `Keras`。`Keras` 使神经网络的编写过程更简单。为了展示有多简单，你将用几行代码构建一个完全连接的简单网络。\n",
    "\n",
    "我们会将在前几课学习的概念与 `Keras` 提供的方法关联起来。\n",
    "\n",
    "该示例的一般流程是首先加载数据，然后定义网络，最后训练网络。\n",
    "\n",
    "\n",
    "## 用 Keras 构建神经网络\n",
    "\n",
    "要使用 Keras，你需要知道以下几个核心概念。\n",
    "\n",
    "## 序列模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "#Create the Sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keras.models.Sequential](https://keras.io/models/sequential/) 类是神经网络模型的封装容器。它会提供常见的函数，例如 `fit()`、`evaluate()` 和 `compile()`。我们将介绍这些函数（在碰到这些函数的时候）。我们开始研究模型的层级吧。\n",
    "\n",
    "\n",
    "## 层级\n",
    "\n",
    "Keras 层级就像神经网络层级。有完全连接的层级、最大池化层级和激活层级。你可以使用模型的 `add()` 函数添加层级。例如，简单的模型可以如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "#创建序列模型\n",
    "model = Sequential()\n",
    "\n",
    "#第一层级 - 添加有 32 个节点的输入层\n",
    "model.add(Dense, input_dim=32)\n",
    "\n",
    "#第二层级 - 添加有 128 个节点的完全连接层级\n",
    "model.add(Dense(128))\n",
    "\n",
    "#第三层级 - 添加 softmax 激活层级\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#第四层级 - 添加完全连接的层级\n",
    "model.add(Dense(10))\n",
    "\n",
    "#第五层级 - 添加 Sigmoid 激活层级\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras` 将根据第一层级自动推断后续所有层级的形状。这意味着，你只需为第一层级设置输入维度。\n",
    "\n",
    "上面的第一层级 `model.add(Flatten(input_dim=32))` 将维度设为 `32`（表示数据来自 `32` 维空间）。第二层级获取第一层级的输出，并将输出维度设为 `128` 个节点。这种将输出传递给下一层级的链继续下去，直到最后一个层级（即模型的输出）。可以看出输出维度是 `10`。\n",
    "\n",
    "构建好模型后，我们就可以用以下命令对其进行编译。我们将损失函数指定为我们一直处理的 `categorical_crossentropy`。我们还可以指定优化程序，稍后我们将了解这一概念，暂时将使用 `adam`。最后，我们可以指定评估模型用到的指标。我们将使用准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用以下命令来查看模型架构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后使用以下命令对其进行拟合，指定 epoch 次数和我们希望在屏幕上显示的信息详细程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, nb_epoch=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意：在 Keras 1 中，nb_epoch 会设置 epoch 次数，但是在 Keras 2 中，变成了 epochs。\n",
    "\n",
    "最后，我们可以使用以下命令来评估模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很简单，对吧？我们实践操作下。\n",
    "\n",
    "## 练习\n",
    "\n",
    "我们从最简单的示例开始。在此测验中，你将构建一个简单的多层前向反馈神经网络以解决 XOR 问题。\n",
    "\n",
    "- 1.将第一层级设为 Flatten() 层级，并将 input_dim 设为 2。\n",
    "- 2.将第二层级设为 Dense() 层级，并将输出宽度设为 8。\n",
    "- 3.在第二层级之后使用 softmax 激活函数。\n",
    "- 4.将输出层级宽度设为 2，因为输出只有 2 个类别。\n",
    "- 5.在输出层级之后使用 softmax 激活函数。\n",
    "- 6.对模型运行 10 个 epoch。\n",
    "\n",
    "准确度应该为 `50%`。可以接受，当然肯定不是太理想！在 `4` 个点中，只有 `2` 个点分类正确？我们试着修改某些参数，以改变这一状况。例如，你可以增加 `epoch` 次数。如果准确率达到 `75%`，你将通过这道测验。能尝试达到 `100%` 吗？\n",
    "\n",
    "首先，查看关于模型和层级的 `Keras` 文档。 [Keras多层感知器](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) 网络示例和你要构建的类似。请将该示例当做指南，但是注意有很多不同之处。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step\n",
      "\n",
      "Accuracy:  0.75\n",
      "\n",
      "Predictions:\n",
      "[[  5.87797523e-01   2.86213798e-03]\n",
      " [  9.99997735e-01   9.84173298e-01]\n",
      " [  2.86771956e-06   4.39027353e-04]\n",
      " [  4.92901206e-01   4.57421131e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "# Using TensorFlow 1.0.0; use tf.python_io in later versions\n",
    "# tf.python.control_flow_ops = tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Our data\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# One-hot encoding the output\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "\n",
    "# Add required layers\n",
    "xor.add(Dense(32, input_dim=2))\n",
    "xor.add(Activation('sigmoid'))\n",
    "xor.add(Dense(2))\n",
    "xor.add(Activation('sigmoid'))\n",
    "\n",
    "# Specify loss as \"binary_crossentropy\", optimizer as \"adam\",\n",
    "# and add the accuracy metric\n",
    "xor.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "# xor.summary()\n",
    "\n",
    "# Fitting the model\n",
    "history = xor.fit(X, y, epochs=2000, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：在没有做完这个练习，请不要看解决方案\n",
    "\n",
    "\n",
    "## 解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step\n",
      "\n",
      "Accuracy:  0.75\n",
      "\n",
      "Predictions:\n",
      "[[  5.55763066e-01   2.04930007e-02]\n",
      " [  9.99899983e-01   8.93629968e-01]\n",
      " [  9.66945809e-05   2.02443730e-03]\n",
      " [  5.43945789e-01   3.96637954e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "# tf.python.control_flow_ops = tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Our data\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# One-hot encoding the output\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "xor.add(Dense(32, input_dim=2))\n",
    "xor.add(Activation(\"sigmoid\"))\n",
    "xor.add(Dense(2))\n",
    "xor.add(Activation(\"sigmoid\"))\n",
    "\n",
    "xor.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "# xor.summary()\n",
    "\n",
    "# Fitting the model\n",
    "history = xor.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新技巧\n",
    "\n",
    "我们的准确率达到了 `75%`，甚至会达到 `100%`，但是并不轻松！\n",
    "\n",
    "这也暗示了在现实生活中，神经网络训练起来有点难。解决有 4 个数据点的简单 XOR 问题就需要一个庞大的架构！并且我们知道（理论上）具有 2 个隐藏节点的 2 层网络可以做到。\n",
    "\n",
    "现在我们尝试一项任务。回到测验，并执行以下步骤：\n",
    "\n",
    "- 将架构改为仅具有 1 个隐藏层，长度为 4。\n",
    "- 加此层的激活函数设为 relu（我们稍后将学习这一概念）。\n",
    "- 将 epoch 次数设为 100。\n",
    "\n",
    "现在测试上面的代码进行运行。准确率是多少？像我一样达到 `100%` 了吗？很神奇，对吧？似乎 `relu` 很有用。\n",
    "\n",
    "在下面的几个部分，我们将学习几个类似的训练优化技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讲的比较好的博客：\n",
    "\n",
    "\n",
    "\n",
    "- 正态分布：就是正常的分布状态，也可以说大多数的数据呈现的状态就可以定一个标准，比如+=5，这个正负5就是标准差 http://blog.sina.com.cn/s/blog_6406a7740102v3fc.html\n",
    "\n",
    "- Keras: https://blog.csdn.net/sinat_26917383/article/details/72857454###;\n",
    "\n",
    "\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/Keras/Keras-intro-1.jpeg\" alt=\"\" />\n",
    "\n",
    "<img src=\"../../../sources/img/NeuralNetworkIntro/Keras/Keras-intro-2.jpeg\" alt=\"\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
